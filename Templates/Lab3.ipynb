{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "docs = [\"Natural Language Processing with Python\",\n",
    "        \"Handbook of Natural Language Processing\",\n",
    "        \"Learning IPython for Interactive Computing and Data Visualization\"]\n",
    "\n",
    "# We have three documents (book titles), first two are about a similar\n",
    "# subject, last one is different. Lets tokenize the documents and\n",
    "# normalize them to lowercase.\n",
    "\n",
    "tokenized_documents = [re.findall(r'\\w+', d.lower()) for d in docs]\n",
    "tokenized_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: 'C:\\\\Users\\\\Sricharan\\\\Desktop\\\\information_retrieval\\\\lab2\\\\1.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9944\\50048276.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'.I'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m             \u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'C:\\\\Users\\\\Sricharan\\\\Desktop\\\\information_retrieval\\\\lab2\\\\{line[3:len(line)-1]}.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'x'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'.T'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'.B'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'.A'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'.W'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'C:\\\\Users\\\\Sricharan\\\\Desktop\\\\information_retrieval\\\\lab2\\\\1.txt'"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "punctuations='''()-[]{};:\\/,.<>@$''^+1234567890*%&=?'''\n",
    "\n",
    "with open('D:\\Downloads\\cran\\cran.all.1400','r') as f:\n",
    "    for line in f:\n",
    "        if line[:2]=='.I':\n",
    "            file=open(f'C:\\\\Users\\\\Sricharan\\\\Desktop\\\\information_retrieval\\\\lab2\\\\{line[3:len(line)-1]}.txt','x')\n",
    "        elif line[:2] in ['.T','.B','.A','.W']:\n",
    "            continue\n",
    "\n",
    "        elif line =='':\n",
    "            file.close()\n",
    "        else:\n",
    "            no_punct_line=\"\"\n",
    "            for char in line:\n",
    "                if(char not in punctuations):\n",
    "                    no_punct_line+=char\n",
    "            file.write(no_punct_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "tokens = {}\n",
    "\n",
    "for i in range(1, 1401):\n",
    "    file = open(f'C:\\\\Users\\\\Sricharan\\\\Desktop\\\\information_retrieval\\\\lab2\\\\{i}.txt')\n",
    "    for line in file:\n",
    "        for word in line.split():\n",
    "            w = str(ps.stem(word))\n",
    "            if w in tokens:\n",
    "                tokens[w][0] = len(tokens[w][1])\n",
    "                tokens[w][1].add(i)\n",
    "            else:\n",
    "                tokens[w] = [1,set()]\n",
    "                tokens[w][1].add(i)\n",
    "        # tokens[w] = 1\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_tokens=dict(sorted(tokens.items(),key=lambda x:x[1][0],reverse=True))\n",
    "#print(sorted_tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "words = list(sorted_tokens.keys())\n",
    "temp = list(sorted_tokens.values())\n",
    "count, freq = [], []\n",
    "for i in range(len(temp)):\n",
    "    count.append(len(temp[i][1]))\n",
    "    freq.append(list(temp[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "from nltk import word_tokenize\n",
    "from os import listdir\n",
    "from os.path import isfile, join, abspath\n",
    "import numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tokens</th>\n",
       "      <th>DOC Frequency</th>\n",
       "      <th>Document ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>of</td>\n",
       "      <td>1394</td>\n",
       "      <td>[1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "      <td>1390</td>\n",
       "      <td>[1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>1341</td>\n",
       "      <td>[1, 2, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>1306</td>\n",
       "      <td>[1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>1251</td>\n",
       "      <td>[1, 2, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Tokens  DOC Frequency                                        Document ID\n",
       "0     of           1394  [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...\n",
       "1    the           1390  [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...\n",
       "2    and           1341  [1, 2, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,...\n",
       "3      a           1306  [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...\n",
       "4     to           1251  [1, 2, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, ..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_tokens = {'Tokens': words, 'DOC Frequency':count, 'Document ID': freq}\n",
    "df = pd.DataFrame.from_dict(dict_tokens)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_tokens = {'Tokens': words, 'DOC Frequency':count, 'DocumentID': freq}\n",
    "df = pd.DataFrame.from_dict(dict_tokens).set_index(\"Tokens\")\n",
    "stopwords = df.head(30)\n",
    "df.drop(index=df.index[:30], axis=0, inplace=True)\n",
    "stopwords.to_csv('stopwords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sort_values('Tokens')\n",
    "df.to_csv('index.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tokens</th>\n",
       "      <th>DOC Frequency</th>\n",
       "      <th>DocumentID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaaero</td>\n",
       "      <td>1</td>\n",
       "      <td>[1111]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaaeroconf</td>\n",
       "      <td>1</td>\n",
       "      <td>[899]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aasu</td>\n",
       "      <td>1</td>\n",
       "      <td>[722]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ab</td>\n",
       "      <td>3</td>\n",
       "      <td>[744, 924, 1381]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abbott</td>\n",
       "      <td>1</td>\n",
       "      <td>[1340]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tokens  DOC Frequency        DocumentID\n",
       "0      aaaero              1            [1111]\n",
       "1  aaaeroconf              1             [899]\n",
       "2        aasu              1             [722]\n",
       "3          ab              3  [744, 924, 1381]\n",
       "4      abbott              1            [1340]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_df=pd.read_csv(\"index.csv\")\n",
    "index_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "\n",
    "# def get_cos_similarity_matrix(v1, v2):\n",
    "#   num = 0\n",
    "#   denom1 = 0\n",
    "#   denom2 = 0\n",
    "#   for i, v in enumerate(v1):\n",
    "#     num += v1[i] * v2[i]\n",
    "#     denom1 += v1[i] * v1[i]\n",
    "#     denom2 += v2[i] * v2[i]\n",
    "#   return (num / (math.sqrt(denom1) * math.sqrt(denom2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def cosine_sim(vec1, vec2):\n",
    "    vec1 = list(vec1.values())\n",
    "    vec2 = list(vec2.values())\n",
    "    dot_prod = 0\n",
    "    for i, v in enumerate(vec1):\n",
    "        dot_prod += v * vec2[i]\n",
    "    mag_1 = math.sqrt(sum([x**2 for x in vec1]))\n",
    "    mag_2 = math.sqrt(sum([x**2 for x in vec2]))\n",
    "    return dot_prod / (mag_1 * mag_2)\n",
    "\n",
    "# Lets compare the first document to the other two. As expected\n",
    "# document 1 and 2 have some similarity, documents 1 and 3 have\n",
    "# 0 similarity since they don't share any words.\n",
    "\n",
    "print(cosine_sim(doc_tfidf_vectors[0], doc_tfidf_vectors[1]))\n",
    "print(cosine_sim(doc_tfidf_vectors[0], doc_tfidf_vectors[2]))\n",
    "\n",
    "                                                                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTermDocFreqDict(tokenized_documents):\n",
    "  df = {}\n",
    "  for doc in tokenized_documents:\n",
    "    for term in doc.termList:\n",
    "      if term in df:\n",
    "        df[term] += 1\n",
    "      else:\n",
    "        df[term] = 1\n",
    "  return df\n",
    "print('\\nCalculating document frequency df for all terms')\n",
    "term_df_dict = buildTermDocFreqDict(tokenized_documents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9 (tags/v3.7.9:13c94747c7, Aug 17 2020, 16:30:00) [MSC v.1900 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f21c6045f170b622cc5cdf49d23e45d81cd353c1d34e05b260529b713e28859f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
